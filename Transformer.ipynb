{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ed2a0d9-a565-46cd-9662-c9989dd0314a",
   "metadata": {},
   "source": [
    "# Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde76586-a35a-4143-9a56-4e0f836a05f1",
   "metadata": {},
   "source": [
    "# https://github.com/shreydan/multilingual-translation/blob/main/en-hi-te-translation.ipynb"
   ]
  },
  {
   "cell_type": "raw",
   "id": "39b61bcc-4128-4563-8852-883a0345874b",
   "metadata": {},
   "source": [
    "# What is transformer?\n",
    "\n",
    "Its deep learning model, which was introduced by google in 2017 ( attention is all you need paper). \n",
    "its is designed to handle sequential data by using an attention machenism instead of relying on RNN layers. \n",
    "\n",
    "its orignally designed for NLP usecase and its is applied in computer-vision, time-series and many other usecase. \n",
    "\n",
    "# Why transformer?\n",
    "\n",
    "RNN having difficulty in capturing long range dependency due to the vanishing gradient problem.\n",
    "\n",
    "Solution- \n",
    "in transformer we have parellel processing on entire sequences. \n",
    "self-attention machenism enables learning long-range dependencies directly. \n",
    "\n",
    "\n",
    "#key component of transformer \n",
    "Encoder & Decoder - The orignal tranformer consist of two block Encoder and decoder. Encoder to process the input text and decoder to generate the output text (one at a time). like in case of language translation (English to german) we will pass Engilsh text into encoder and decoder will generate the german text one at a time.  \n",
    "\n",
    "\n",
    "#What kind of normalization we use in transformer? why its different from batch normalization ? explain issues with batch normalizatio?\n",
    "\n",
    "\n",
    "# what is differenr between batch normalization and layer normalization?\n",
    "\n",
    "https://www.youtube.com/watch?v=2V3Uduw1zwQ\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b2ea5238",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "#https://viewer.diagrams.net/?tags=%7B%7D&lightbox=1&highlight=0000ff&edit=_blank&layers=1&nav=1#R%3Cmxfile%3E%3Cdiagram%20name%3D%22Page-1%22%20id%3D%22-Zgw1XNkuYuAmMOekjRC%22%3E7V1dd%2BI4Ev01Oad3z%2BkcS%2FLnY%2BdjZ89ustO96Z2deXTAAW8AM8Yk0L9%2BZZAMVsmgdMAlQ%2FqlQWBHSLdKdVV15Qt2PV78ksfT4X3WT0YX1OkvLtjNBaXE8Rz%2BX9myFC0BCdYtgzzti7ZNw0P6I5GXitZ52k9mtS8WWTYq0mm9sZdNJkmvqLXFeZ691r%2F2lI3qf3UaDxLQ8NCLR7D1v2m%2FGK5bQ%2Fm7yva%2FJ%2BlgKP8yccQn41h%2BWTTMhnE%2Fe91qYrcX7DrPsmL9ary4Tkbl6MlxWV%2F3t4ZPq47lyaQwuWAQvCz%2F%2FMfz3ey1dzv7RsKhk91%2BFnd5iUdz8YNFZ4ulHIE8m0%2F6SXkT54JdvQ7TInmYxr3y01c%2B6bxtWIxH%2FB3hL8XtkrxIFo39JNWv57hJsnFS5Ev%2BFXGBL6deQMaVY%2F26Gf9AjvJwa%2BxZhbZYTPqguvlmXPgLMTRvGCY4Kkmfw0S8zfJimA2ySTy63bRe1cdt8527LJuK0fpfUhRLgfl4XmS6sSz%2F0O6R5P3K5nkv2dF%2FJiwnzgdJset3Uv3U5MkoLtKXekcOPsoMgPF7sih4y3WWT%2BczdGR6rI7MzxQik1ANMv1j4dLFwCUfrXz5e3n9pSff%2FiFut3pzs6i9W4p3B8RzYIhn4ugntB08e014%2Fp49JxOI53Jo7uJHvoTWxjsepYMJf93jw5TkvKEEccqXqC%2Fig3Ha76%2BnNpmlP%2BLH1f3KEZ9m6aRY%2FSrv6sK72WUFYv0UF29Wre3ZaYZgo8k4l8SJSM1qhC81ngJx76%2Flb9ncRbkge3qacSSoM1Z16Ocn0QeT%2BDWbpUVamswqGGmcyu4sD8bm9N7lYXXplzyPl1tfECiFUy0wxFf7OoAcJdBRvk%2F8nd%2FnL9Y9OChMAmjremTwMHBavuzNH5P9q9bjGiV3j1VD3HserLDz67wYpZNEtPfj%2FPlXfpu0WLnbS8erN9JV64EWQqqEaJHhOhgeax0MO26ApvFZgLmcRR0fZAna%2FVFww5rWzjDLbqquhDfdjh%2BTfj%2BdDMBMbMaZtBIKc65V97EudihMCBiU84iFCe0GrCmA9VQEUlYhmyhrmwXIZueKbNcU2T4qsl2AbHvgHPmKo3bQ4eydK5z9bsAZMl574OxFem6HCOfgTOEsN3L27xrgwjkEcD7BXTjSwAw323AeFfztZzfejr%2FVRlAYZqdMCTWEp5CZmu6Fds%2Bgoj0G5Ud%2BbSWSqVR7zUt2xqZkr5rrldHq1nLuuZrlnDrsWAu6HJXz2MoNwvoMhNhbuRSF7R7SmZuyVtYwMy05c8hav272Yy7olYyQdu7OSBMYJouYj3jpnJM85T0sPbps%2FSqb6H4reUoXiSwDOlS2wqlDnJnu6BwP4%2BdKgakpBWYU1Taak76qbfjxuETw5HE2XQ2VPypKb52%2B8JeD8uWW7aw%2F4z3a%2BriTFhUoLJxpSrRatqhzZeFMFkXutShc6tD5DK3xOIeo49z1JK35OKPuKkn20bK%2FWaTF79Kj8NcrX3NJPfF2423KN9LZbJxUzUVtPJZFTsp7b4GDviLIqy9XnqMsQ%2BsfIC7aIAPch9VzKcSNlButfyC40VsrnpjaX293t%2BpfJ37QQsETg7sJd%2FGSBynU%2BVeWj%2BNR%2BiNeB0wNAc40z3rJbGZAnBt48gECGZUauKaVTEdLJzC4%2B9C9YVXjQw89S8PONYfOTHcjXNRSaQZ3I%2B44JOMS9yv8f%2Fo2T%2FLlX8Astr1h6daR7eMj%2B1z3EpjpXoKLupfA4F6Cgux%2FJhbgWl0JLQD22VL60BTYqJSewcS6Auzfyk%2Fwoc2UEigLoI2c6EYjgnL13A9tVHYvu7kF7X%2BXOehEs797FRe9If%2Fuatgp%2F3vOZD5eASnuz9YNqy1g%2Fv9NOl43lLli%2Fcax4eZwPy7ihyLLV%2BJlhA1ghVAHRGNROonu0fZ%2FXdzqb4JnUbQbFgVp7YdF7ZJUWWBS50qZXVPK7DFUk4KU%2BcOkanFfUI%2F7LDApqAj%2F8%2Fn7uZqZMX9Hzai5kL%2Ffx0WeLnjb%2FXy03pfiFqNn8cNs%2FDg32Iw9ANwrCiMruQJDmnM8uENR9DccuB8Stqbs3EMt73IhO1%2B5Guev5Y9cnW8E5mE0SqczA199BLASR%2Bec20VrBEas41D1jNOuqIGMB9n2wyfuKKA77WQlubu7kvyzc0mlscos5PqdvZXkEljbM5Y9FeN4oZ83BH9CTAuZj7bJ50HK23V%2FYnpMheeh%2BhN4jlgZqJUIva8Qev0bBkzVYxP0MJUpvXZgCmlk12HqmcK0wTO3BFNIBr8m%2BXheCIb%2Bkiav%2FL9smuT6io8WvGqowJXporR24QrpWNfhanr6lo9KKDxI5r4UBf%2B120XxZqVKCMD1dZqPdoELCdnW%2BHUbwZGpw0U9v8qDBK%2BesLYBqLrTbtsFqg%2FpWMfx6ZvyYB%2BVB%2FuQVTX4U%2BcTRSFZKlgD9OjVPzmS5ZuSLB%2BVZPmQZNnnTCPdAc3t4vPk2JVvyq581MXeh%2BzqJs%2Bm2byAWU10oFLHRwfqyfEq35RXBaiV776GV%2FX4n62W%2Bl9u7%2F5jw2qvP2urXZCiqEi3cuUU7cB708JJQt6bLVeyCfKpHMoh3CQ01L4dKufgn%2BvhUG%2BYetQSvwDyRhkR4vsu7ZkfrfquAKdCVSqGL6VI%2BI%2BtT%2FSC4QNiV6oZ96%2FB7yUzeq8VKHItT31CUIPy91BOK0AJomxwWqYsITyS4ls51ipQjws78moVdP0UK%2FMJRI2eA5QnIGGMc4BaBRlAOt19WbqP%2FvyuwO%2FS%2BoAcTISmhD6k7awpKgM6djBxroLYwLTkNkQVxAZ7BbFWKL1VL6iVRbTrBc%2BV2oem1D5EZfZhM7O3S%2BmtPuwiQFd6h7i6VDyld2jK%2FEPUIjzZzQ8RXYNJ%2BcoOSsg0JtWqiC7E1aXiSb1DU10qskl96FJ3m1ToWGdSKGdIHdI0TLWkEW4gBZPsH6ZRC%2BAUybYFpgHT83YeTOcz22hd2CBBPU%2BqZ1ojHaFW%2BctuWq92D9RHUOsqqFrVD0eQJXdf7R6Zlk5HqFtvspuWqt19ZcuNOOhPTI8g8e06VE3pEW4MGMHC6VNSu69x1WgJXVS7R5DQIqvdgT%2Bhpqvf0YK9CCaIu%2B5PjDklamY%2B0pxPZInaPVTYnB6mrVbhRZDOdR2mpslR4jS45pZwCtmgbXL3wFPl7rowrV28ntyhRNX2jcHDblEBW3W0G4p3ouwqE%2FxjrokDadmpaN6FNzXyu6gVklVHbVJqAk%2Fr6TZ6W%2FW0xIHErPMYNaXExEHlxFVHTaTvDCWUVdLgNEQ%2Fp4E4J0e5BAyNAItKuqqO2uRUVYwyB12wSZyT41sCeUZ6POSFHzIueyTwAKwE%2FWgx4pwe2SLGZIvgki2iIVtWyOABUCk%2BUAlyVSlaFl2g1Gjz4L0JSSXPICtUnOCyzl2Yr4pKj6wtrAbBBqU1MA98pTUhkMl96fdTrF2HLbsJfkpvJRVWWxWnVom337%2FDobc1QpQiDxJQM1PT3EoRb3nqnRrEW299dHNE9H%2BnsWPgYc9vvYB4%2Fp4riJouVK64OMoDoglB0eZ2VNxIqKkQWOzhHtzafEU8QyK1%2BOTI%2BkZCzvVRtuLkFqPJRw7Tu%2FE02zCklyqa8dMh5FwFvOJQKiN8o9YRVh21XupIHOUZnCREf%2BIFDzRwAV6Dd5vSrGqcDQCOeixm1dEPCUpTapKqZ3PqTglpVYNCKO5%2BD57kUYQ7XbAruCfzYVf1kMxCu%2Br6KV2EGmf4GW5gRT9UwfsCOr8e0FlhIJpjv6xUPwbEPrpHIVc%2BX%2F2jWJ%2BNVnLU4wuqjtovgYyUFZXoapJaVZURCvlz90WQApFGqyzu9pzsqKU6yEARhGyQiIdYBglx1%2BFqnrhDDgoZrA8%2FJS2kwFajOXRRDFmByx41JPAq2meotRv7sdMrJmfmVBO3mJxBqmmLIjJSOR7%2B4%2F6qv3ZKUDVOpzLcMnIGKaJtokigfPDQH%2FpH2NkmUpm52hc5tNuXSLUByoFuh61lKCOnTPGg7BqzFIr6pEsiUWNH9i3Yl35Drhp9w7y%2Be%2FHVF7IRotg5CUl0GW398%2Bq3bKhr05ReOqoDMXwI2lurSDnk1cpXb19ZqKf2TdTzHbfI09VIvHfVWnePxLu7Sbxz6XgyYhZD%2F1m8tZjFSyPdJ7jFedB0qMrDtQt1u4zePT1G7xozehd5BTaWh%2B%2FRNbZeh%2BpCtRB%2BYtJtzuq%2BzdTrw3mA8eKspdUB42%2FzLCu2nSv%2FkcP7rF8uUrf%2FBw%3D%3D%3C%2Fdiagram%3E%3C%2Fmxfile%3E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5957af72-2293-44e1-bb83-71c692d11759",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "651b08c4-5051-4ae2-8f4e-28078829fed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2021 NVIDIA Corporation\n",
      "Built on Wed_Jul_14_19:47:52_Pacific_Daylight_Time_2021\n",
      "Cuda compilation tools, release 11.4, V11.4.100\n",
      "Build cuda_11.4.r11.4/compiler.30188945_0\n"
     ]
    }
   ],
   "source": [
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "290b27d8-774c-4a45-81f4-946403c68875",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a92ebf9e-1114-4e1e-b9f0-bbc93ccd896e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip uninstall torchtext\n",
    "#!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37c5faf3-dd0e-4a12-a79e-2c0fa06e7846",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da04d80a-67e8-4f42-8534-190b3411cbbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nupur\\Documents\\repo\\env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import random\n",
    "from tokenizers import Tokenizer\n",
    "from tokenizers.trainers import WordPieceTrainer\n",
    "from tokenizers.models import WordPiece\n",
    "from tokenizers import normalizers\n",
    "from tokenizers.normalizers import Lowercase\n",
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "from tokenizers import decoders\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "from torch.amp import autocast,GradScaler\n",
    "import gc\n",
    "import torch\n",
    "\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a35e18b4-ba42-41aa-838b-4014182b4fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1 = load_dataset(\"opus100\", \"en-hi\")\n",
    "df1_train = pd.DataFrame(dataset1['train']['translation'],columns=['en','hi'])\n",
    "df1_train.rename(columns={'en':'lang1','hi':'lang2'},inplace=True)\n",
    "df1_val = pd.DataFrame(dataset1['validation']['translation'],columns=['en','hi'])\n",
    "df1_val.rename(columns={'en':'lang1','hi':'lang2'},inplace=True)\n",
    "df1_test = pd.DataFrame(dataset1['test']['translation'],columns=['en','hi'])\n",
    "df1_test.rename(columns={'en':'lang1','hi':'lang2'},inplace=True)\n",
    "df1_train['lang2_id'] = 'hi'\n",
    "df1_val['lang2_id'] = 'hi'\n",
    "df1_test['lang2_id'] = 'hi'\n",
    "\n",
    "dataset2 = load_dataset(\"opus100\", \"en-te\")\n",
    "df2_train = pd.DataFrame(dataset2['train']['translation'],columns=['en','te'])\n",
    "df2_train.rename(columns={'en':'lang1','te':'lang2'},inplace=True)\n",
    "df2_val = pd.DataFrame(dataset2['validation']['translation'],columns=['en','te'])\n",
    "df2_val.rename(columns={'en':'lang1','te':'lang2'},inplace=True)\n",
    "df2_test = pd.DataFrame(dataset2['test']['translation'],columns=['en','te'])\n",
    "df2_test.rename(columns={'en':'lang1','te':'lang2'},inplace=True)\n",
    "df2_train['lang2_id'] = 'te'\n",
    "df2_val['lang2_id'] = 'te'\n",
    "df2_test['lang2_id'] = 'te'\n",
    "train_df = pd.concat([df1_train,df2_train]).reset_index(drop=True)\n",
    "val_df = pd.concat([df1_val,df2_val]).reset_index(drop=True)\n",
    "test_df = pd.concat([df1_test,df2_test]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b673ca12-3b4c-4250-b792-fde4d141d96d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(598671, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "74001604-5eee-4679-998d-514eedb56577",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lang1</th>\n",
       "      <th>lang2</th>\n",
       "      <th>lang2_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>598661</th>\n",
       "      <td>Right, put your hands in front of you like this.</td>\n",
       "      <td>రైట్, ఈ వంటి మీరు ముందు మీ చేతులు చాలు.</td>\n",
       "      <td>te</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598662</th>\n",
       "      <td>Damn right.</td>\n",
       "      <td>డామన్ కుడి.</td>\n",
       "      <td>te</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598663</th>\n",
       "      <td>We got kids, we can't afford to do this.</td>\n",
       "      <td>మేము పిల్లలు వచ్చింది , మేము దీన్ని పొందలేని.</td>\n",
       "      <td>te</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598664</th>\n",
       "      <td>Hmm.</td>\n",
       "      <td>అయ్యో.</td>\n",
       "      <td>te</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598665</th>\n",
       "      <td>He's lost the will to live</td>\n",
       "      <td>అతనుకోల్పోతేజీవించాలనే</td>\n",
       "      <td>te</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598666</th>\n",
       "      <td>Sad life.</td>\n",
       "      <td>సాడ్ జీవితం.</td>\n",
       "      <td>te</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598667</th>\n",
       "      <td>Are you taking your driver's test drunk?</td>\n",
       "      <td>మీరు మీ డ్రైవర్ యొక్క పరీక్ష తాగిన తీసుకున్నట...</td>\n",
       "      <td>te</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598668</th>\n",
       "      <td>Initiate recall.</td>\n",
       "      <td>రీకాల్ ప్రారంభించు.</td>\n",
       "      <td>te</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598669</th>\n",
       "      <td>No. You need to come see me right now.</td>\n",
       "      <td>నంఇప్పుడేచూడండిమీరు రావాలి.</td>\n",
       "      <td>te</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598670</th>\n",
       "      <td>All right.</td>\n",
       "      <td>అన్ని కుడి.</td>\n",
       "      <td>te</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   lang1  \\\n",
       "598661  Right, put your hands in front of you like this.   \n",
       "598662                                       Damn right.   \n",
       "598663          We got kids, we can't afford to do this.   \n",
       "598664                                              Hmm.   \n",
       "598665                        He's lost the will to live   \n",
       "598666                                         Sad life.   \n",
       "598667          Are you taking your driver's test drunk?   \n",
       "598668                                  Initiate recall.   \n",
       "598669            No. You need to come see me right now.   \n",
       "598670                                        All right.   \n",
       "\n",
       "                                                    lang2 lang2_id  \n",
       "598661           రైట్, ఈ వంటి మీరు ముందు మీ చేతులు చాలు.       te  \n",
       "598662                                        డామన్ కుడి.       te  \n",
       "598663      మేము పిల్లలు వచ్చింది , మేము దీన్ని పొందలేని.       te  \n",
       "598664                                             అయ్యో.       te  \n",
       "598665                             అతనుకోల్పోతేజీవించాలనే       te  \n",
       "598666                                       సాడ్ జీవితం.       te  \n",
       "598667  మీరు మీ డ్రైవర్ యొక్క పరీక్ష తాగిన తీసుకున్నట...       te  \n",
       "598668                                రీకాల్ ప్రారంభించు.       te  \n",
       "598669                        నంఇప్పుడేచూడండిమీరు రావాలి.       te  \n",
       "598670                                        అన్ని కుడి.       te  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.tail(10)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "de53f1fc-ad0c-49ed-83cb-97a30159cb88",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# Wordpiece  - this is used to tokenize the data. here data like \"unhappiness\" become [\"un\", \"##hapiness\"]\n",
    "\n",
    "# normalize - here we using lowecase normalizer which converting data to lowercase before passing this to tokenizer\n",
    "\n",
    "# pretokenizer - ots responsible for splitting the text into tokens before the actual tokenization process, here Whitespace will split the text at whitespace characters.\n",
    "\n",
    "#decoder - this will convert token to human readable text. like  \"un\" and \"##happiness\" would be joined to reconstruct the original word, \"unhappiness\"\n",
    "\n",
    "#trainer - instance from wordpiecetrainer used to train the model on the given data.<s-en> is start for english and so on. \n",
    "\n",
    "#train the model on full data using given trainer. \n",
    "\n",
    "#enable padding - enable paddinig ensures all sequence is in same length. \n",
    "\n",
    "#truncate - truncate the sequence length to have same length for each sequences. \n",
    "\n",
    "# save the tokenizer. \n",
    "\n",
    "# what is permute operation in torch? used to rearrange a tensor in a specified shape.Change dimension order\n",
    "\n",
    "#what is view - Change tensor shape,Requires contiguous memory layout\n",
    "\n",
    "#what is contiguous in torch? this operation ensures that block of data is stored in contiguous block of memory.\n",
    "\n",
    "#what is register buffer in torch? - its uses to register a tensor and it ensures that regidtered tensor is not a learning parameter. \n",
    " you can not do like below as this has to be inside a class which is inherited from nn.Module\n",
    "   torch.nn.Module.register_buffer('constant_tensor', torch.ones(3, 3))\n",
    "\n",
    "# what is torch.tril - it extracts the lower triangular part of the a tensor by zeroing out all the elements above the main tringle.\n",
    "\n",
    "\n",
    "torch.tril(torch.ones(1, 1, 4,4))\n",
    "\n",
    "tensor([[[[1., 0., 0., 0.],\n",
    "          [1., 1., 0., 0.],\n",
    "          [1., 1., 1., 0.],\n",
    "          [1., 1., 1., 1.]]]])\n",
    "\n",
    "\n",
    "# Mask - this will help to determine which data need to be proceed in the network and which need to be ignored. \n",
    "\n",
    "# embedding - first we passing src to the embedding and then we adding positional embedding to this which means embedidng is sum of actual embedding and positional embedding \n",
    "\n",
    "#positional embedding - this show the position of the data. for getting this we take the position on the token (start form 0 and till len of the data)\n",
    "and pass this postion to the embedding layer. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "259fd9ae-b9ab-4d42-b5b3-10ac61cba4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = pd.concat([train_df,val_df])\n",
    "lang1,lang2 = list(full_df['lang1']), list(full_df['lang2'])\n",
    "full = lang1+lang2\n",
    "random.shuffle(full)\n",
    "\n",
    "bert_tokenizer = Tokenizer(WordPiece(unk_token=\"<unk>\"))\n",
    "bert_tokenizer.normalizer = normalizers.Sequence([Lowercase()])\n",
    "bert_tokenizer.pre_tokenizer = Whitespace()\n",
    "bert_tokenizer.decoder = decoders.WordPiece()\n",
    "trainer = WordPieceTrainer(special_tokens=[\"<unk>\",\"<pad>\",\"<s-en>\",\"<s-hi>\",\"<s-te>\",\"</s>\"])\n",
    "bert_tokenizer.train_from_iterator(full,trainer)\n",
    "bert_tokenizer.enable_padding(\n",
    "    pad_id=bert_tokenizer.token_to_id('<pad>'),\n",
    "    length=128,\n",
    "    pad_token='<pad>'\n",
    ")\n",
    "bert_tokenizer.enable_truncation(128)\n",
    "\n",
    "base = Path('translator/tokenizer',)\n",
    "base.mkdir(exist_ok=True,parents=True)\n",
    "bert_tokenizer.save(str(base / 'en_hi_te.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0faed2ef-0f97-4e72-ba9b-44d12eafa3e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 : <s-hi>\n",
      "5058 : आपने\n",
      "8860 : चैनल\n",
      "3695 : मालिक\n",
      "969 : का\n",
      "23556 : विशेषाधिकार\n",
      "10 : %\n",
      "22 : 1\n",
      "933 : से\n",
      "2837 : वापस\n",
      "1172 : ले\n",
      "1616 : लिया\n",
      "897 : है\n",
      "19 : .\n",
      "5 : </s>\n",
      "\n",
      " आपने चैनल मालिक का विशेषाधिकार % 1 से वापस ले लिया है. \n",
      "\n",
      "\n",
      "4 : <s-te>\n",
      "55 : l\n",
      "10142 : అతనికి\n",
      "17550 : వ్యవ\n",
      "5374 : ##సా\n",
      "534 : ##య\n",
      "2076 : నా\n",
      "4086 : వా\n",
      "4885 : ##టా\n",
      "2526 : వి\n",
      "10364 : ##క్ర\n",
      "13918 : ##యిం\n",
      "4463 : ##చి\n",
      "1814 : ##ంది\n",
      "19 : .\n",
      "5 : </s>\n",
      "\n",
      " l అతనికి వ్యవసాయ నా వాటా విక్రయించింది.\n"
     ]
    }
   ],
   "source": [
    "x = bert_tokenizer.encode(f\"<s-hi>{lang2[12345]}</s>\")\n",
    "for a,b in zip(x.ids, x.tokens):\n",
    "    if b!= '<pad>':\n",
    "        print(f'{a} : {b}')\n",
    "    \n",
    "print('\\n',bert_tokenizer.decode(x.ids),'\\n\\n')\n",
    "\n",
    "x = bert_tokenizer.encode(f\"<s-te>{lang2[-111]}</s>\")\n",
    "for a,b in zip(x.ids, x.tokens):\n",
    "    if b!= '<pad>':\n",
    "        print(f'{a} : {b}')\n",
    "    \n",
    "print('\\n',bert_tokenizer.decode(x.ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5bba22f2-1ac7-4961-9cf4-7c9d666d94cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en 2\n",
      "hi 3\n",
      "te 4\n",
      "eos 5\n",
      "pad 1\n"
     ]
    }
   ],
   "source": [
    "print('en',bert_tokenizer.token_to_id('<s-en>'))\n",
    "print('hi',bert_tokenizer.token_to_id('<s-hi>'))\n",
    "print('te',bert_tokenizer.token_to_id('<s-te>'))\n",
    "print('eos',bert_tokenizer.token_to_id('</s>'))\n",
    "print('pad',bert_tokenizer.token_to_id('<pad>'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e3219eec-5418-4e77-aaa3-4e507688dcd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    def __init__(self,df):\n",
    "        self.df = df\n",
    "    def __len__(self,):\n",
    "        return len(self.df)\n",
    "    def __getitem__(self,idx):\n",
    "        sample = self.df.iloc[idx,:]\n",
    "        en,lang2 = sample['lang1'], sample['lang2']\n",
    "        start_token = \"<s-hi>\" if sample['lang2_id']=='hi' else \"<s-te>\"\n",
    "        en = bert_tokenizer.encode(f'<s-en>{en.strip()}</s>').ids\n",
    "        l2 = bert_tokenizer.encode(f'{start_token}{lang2.strip()}</s>').ids\n",
    "        l2_shift = l2.copy()\n",
    "        l2_shift[:-1] = l2[1:]\n",
    "        l2_shift[-1] = bert_tokenizer.token_to_id('<pad>')\n",
    "        \n",
    "        en = torch.tensor(en,dtype=torch.long)\n",
    "        l2 = torch.tensor(l2,dtype=torch.long)\n",
    "        l2_shift = torch.tensor(l2_shift,dtype=torch.long)\n",
    "        l2_shift[l2_shift==1]=-100\n",
    "        return en,l2,l2_shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5e62ffd2-f5e3-4c3d-aae6-29f09316d283",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = Dataset(train_df)\n",
    "val_ds = Dataset(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5af43b4c-433a-425f-9720-5e34e2a3b0c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "english tokens\n",
      " tensor([   2, 1716,   17, 7303, 2171,    5,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1])\n",
      "lang2 tokens\n",
      " tensor([   3, 3372,   17, 1048, 3302, 2934,    5,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1])\n",
      "right-shifted lang2 tokens\n",
      " tensor([3372,   17, 1048, 3302, 2934,    5, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100])\n"
     ]
    }
   ],
   "source": [
    "print('english tokens\\n',train_ds[0][0])\n",
    "print('lang2 tokens\\n',train_ds[0][1])\n",
    "print('right-shifted lang2 tokens\\n',train_ds[0][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4e3f53d7-7f84-40d3-81be-cf3881ca2a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embedding(nn.Module):\n",
    "    def __init__(self,vocab_size,max_len,dim):\n",
    "        super().__init__()\n",
    "        self.max_len = max_len\n",
    "        self.class_embedding = nn.Embedding(vocab_size,dim)\n",
    "        self.positional_embedding = nn.Embedding(max_len,dim)\n",
    "    def forward(self,x):\n",
    "        x = self.class_embedding(x)\n",
    "        pos = torch.arange(0,x.size(1),device = x.device)\n",
    "        x = x+ self.positional_embedding(pos)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "37b1df36-f57b-410c-a634-9f1b8eafee05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dim': 128,\n",
       " 'n_heads': 4,\n",
       " 'attn_dropout': 0.1,\n",
       " 'mlp_dropout': 0.1,\n",
       " 'depth': 8,\n",
       " 'vocab_size': 30000,\n",
       " 'max_len': 128,\n",
       " 'pad_token_id': 1}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\n",
    "    'dim': 128,\n",
    "    'n_heads': 4,\n",
    "    'attn_dropout': 0.1,\n",
    "    'mlp_dropout': 0.1,\n",
    "    'depth': 8,\n",
    "    'vocab_size': bert_tokenizer.get_vocab_size(),\n",
    "    'max_len': 128,\n",
    "    'pad_token_id': bert_tokenizer.token_to_id('<pad>')\n",
    "}\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ab75baef-388b-4bef-a0e9-79ead7e49fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RMSNorm(nn.Module):\n",
    "    \n",
    "\n",
    "    def __init__(self,d,p = -1.,eps = 1e8,bias = False):\n",
    "        \"\"\"Root mean sruare layer normalization.\n",
    "        \n",
    "        :param d: model size\n",
    "        :param p: partial RMSNorm, valid value [0, 1], default -1.0 (disabled)\n",
    "        :param eps:  epsilon value, default 1e-8\n",
    "        :param bias: whether use bias term for RMSNorm, disabled by\n",
    "            default because RMSNorm doesn't enforce re-centering invariance.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.p = p #disabled\n",
    "        self.d = d\n",
    "        self.eps = eps\n",
    "        self.bias = bias\n",
    "        self.scale = nn.Parameter(torch.ones(d))\n",
    "        self.register_parameter(\"scale\", self.scale)\n",
    "        if self.bias:\n",
    "            self.offset = nn.Parameter(torch.zeros(d))\n",
    "            self.register_parameter(\"offset\", self.offset)\n",
    "        \n",
    "\n",
    "    def forward(self,x):\n",
    "        if self.p <0 or self.p >1:\n",
    "            norm_x = x.norm(2,dim = 1,keepdim = True)\n",
    "            d_x = self.d\n",
    "        else:\n",
    "            partial_size  = int(self.d * self.p)\n",
    "            partial_x,_= torch.split(x,[partial_size,self.d - partial_size],dim = -1)\n",
    "            norm_x = partial_x.norm(2,dim = -1,keepdim=True)\n",
    "            d_x = partial_size\n",
    "\n",
    "        rms_x = norm_x * d_x **(-1./2)\n",
    "        x_normed = x /(rms_x + self.eps)\n",
    "\n",
    "        if self.bias:\n",
    "            return self.scale * x_normed + self.offset\n",
    "        return self.scale * x_normed\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6f3866ee-a3c4-45b0-af4b-0a732240a1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiheadAttention(nn.Module):\n",
    "    def __init__(self, dim, n_heads, dropout=0.):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.n_heads = n_heads\n",
    "        assert dim % n_heads == 0, 'dim should be div by n_heads'\n",
    "        self.head_dim = self.dim // self.n_heads\n",
    "        self.q = nn.Linear(dim,dim,bias=False)\n",
    "        self.k = nn.Linear(dim,dim,bias=False)\n",
    "        self.v = nn.Linear(dim,dim,bias=False)\n",
    "        self.attn_dropout = nn.Dropout(dropout)\n",
    "        self.scale = self.head_dim ** -0.5\n",
    "        self.out_proj = nn.Linear(dim,dim,bias=False)\n",
    "        \n",
    "    def forward(self,q,k,v,mask=None):\n",
    "        batch,t,c = q.shape\n",
    "        q = self.q(q)\n",
    "        k = self.k(k)\n",
    "        v = self.v(v)\n",
    "        q = q.view(batch,q.size(1),self.n_heads,self.head_dim).permute(0,2,1,3)\n",
    "        k = k.view(batch,k.size(1),self.n_heads,self.head_dim).permute(0,2,1,3)\n",
    "        v = v.view(batch,v.size(1),self.n_heads,self.head_dim).permute(0,2,1,3)\n",
    "        \n",
    "        qkT = torch.matmul(q,k.transpose(-1,-2)) * self.scale\n",
    "        qkT = self.attn_dropout(qkT)\n",
    "        \n",
    "        if mask is not None:\n",
    "            mask = mask.to(dtype=qkT.dtype,device=qkT.device)\n",
    "            a,b = qkT.size(-2), qkT.size(-1)\n",
    "            qkT = qkT.masked_fill(mask[:,:,:a,:b]==0,float('-inf'))\n",
    "            \n",
    "        qkT = nn.functional.softmax(qkT,dim=-1)\n",
    "            \n",
    "        attn = torch.matmul(qkT,v)\n",
    "        attn = attn.permute(0,2,1,3).contiguous().view(batch,t,c)\n",
    "        out = self.out_proj(attn)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ad9a7888-6c2c-4f53-b0a6-71e67e924450",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self,dim,dropout=0.):\n",
    "        super().__init__()\n",
    "        self.feed_forward = nn.Sequential(\n",
    "            nn.Linear(dim,dim*4,bias=False),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(dim*4,dim,bias=False)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.feed_forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b40667fd-4ac7-47b7-9759-77f43f9e6293",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderBlock(nn.Module):\n",
    "    def __init__(self, dim, n_heads, attn_dropout=0., mlp_dropout=0.):\n",
    "        super().__init__()\n",
    "        self.attn = MultiheadAttention(dim,n_heads,attn_dropout)\n",
    "        self.ffd = FeedForward(dim,mlp_dropout)\n",
    "        self.ln_1 = RMSNorm(dim)\n",
    "        self.ln_2 = RMSNorm(dim)\n",
    "        \n",
    "    def forward(self,x,mask=None):\n",
    "        x = self.ln_1(x)\n",
    "        x = x + self.attn(x,x,x,mask)\n",
    "        x = self.ln_2(x)\n",
    "        x = x + self.ffd(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f8350ea8-38d9-4a0e-a9cc-8255cf6d5cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self, dim, n_heads, attn_dropout=0., mlp_dropout=0.):\n",
    "        super().__init__()\n",
    "        self.self_attn = MultiheadAttention(dim,n_heads,attn_dropout)\n",
    "        self.cross_attn = MultiheadAttention(dim,n_heads,attn_dropout)\n",
    "        self.ln_1 = RMSNorm(dim)\n",
    "        self.ln_2 = RMSNorm(dim)\n",
    "        self.ln_3 = RMSNorm(dim)\n",
    "        self.ffd = FeedForward(dim,mlp_dropout)\n",
    "        \n",
    "    def forward(self, x, enc_out, src_mask, tgt_mask):\n",
    "        x = self.ln_1(x)\n",
    "        x = x + self.self_attn(x,x,x,tgt_mask)\n",
    "        x = self.ln_2(x)\n",
    "        x = x + self.cross_attn(x,enc_out,enc_out,src_mask) # decoder: q, encoder: k,v\n",
    "        x = self.ln_3(x)\n",
    "        x = x + self.ffd(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "20881a6e-0801-4f48-b587-d3ddfd8f210f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqTransformer(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = Embedding(config['vocab_size'],config['max_len'],config['dim'])\n",
    "        \n",
    "        self.depth = config['depth']\n",
    "        self.encoders = nn.ModuleList([\n",
    "            EncoderBlock(\n",
    "                dim=config['dim'],\n",
    "                n_heads=config['n_heads'],\n",
    "                attn_dropout=config['attn_dropout'],\n",
    "                mlp_dropout=config['mlp_dropout']\n",
    "            ) for _ in range(self.depth)\n",
    "        ])\n",
    "        self.decoders = nn.ModuleList([\n",
    "            DecoderBlock(\n",
    "                dim=config['dim'],\n",
    "                n_heads=config['n_heads'],\n",
    "                attn_dropout=config['attn_dropout'],\n",
    "                mlp_dropout=config['mlp_dropout']\n",
    "            ) for _ in range(self.depth)\n",
    "        ])\n",
    "        \n",
    "        self.ln_f = RMSNorm(config['dim'])\n",
    "        self.lm_head = nn.Linear(config['dim'],config['vocab_size'],bias=False)\n",
    "        \n",
    "        self.embedding.class_embedding.weight = self.lm_head.weight\n",
    "        \n",
    "        self.pad_token_id = config['pad_token_id']\n",
    "        self.register_buffer('tgt_mask',torch.tril(torch.ones(1,1,config['max_len'],config['max_len'])))\n",
    "    \n",
    "        self.apply(self._init_weights)\n",
    "        \n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "    \n",
    "    def create_src_mask(self,src):\n",
    "        return (src != self.pad_token_id).unsqueeze(1).unsqueeze(2) # N, 1, 1, src_len\n",
    "    \n",
    "    def forward(self, src, tgt, labels=None):\n",
    "        \n",
    "        src_mask = self.create_src_mask(src)\n",
    "        \n",
    "        enc_out = self.embedding(src)\n",
    "        dec_out = self.embedding(tgt)\n",
    "        \n",
    "        for i in range(self.depth):\n",
    "            enc_out = self.encoders[i](enc_out,mask=src_mask)\n",
    "            dec_out = self.decoders[i](dec_out,enc_out,src_mask=src_mask,tgt_mask=self.tgt_mask)\n",
    "\n",
    "        dec_out = self.ln_f(dec_out)\n",
    "        \n",
    "        if labels is not None:\n",
    "            lm_logits = self.lm_head(dec_out)\n",
    "            loss = F.cross_entropy(lm_logits.view(-1, lm_logits.shape[-1]), labels.view(-1))\n",
    "            return loss\n",
    "        \n",
    "        lm_logits = self.lm_head(dec_out[:,[-1],:])\n",
    "        return lm_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "75aa66a3-d817-4b5c-8390-48ee68e64292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18709 125\n"
     ]
    }
   ],
   "source": [
    "train_dl = torch.utils.data.DataLoader(train_ds, batch_size=32,shuffle=True,pin_memory=True,num_workers=0)\n",
    "val_dl = torch.utils.data.DataLoader(val_ds, batch_size=32,shuffle=False,pin_memory=True,num_workers=0)\n",
    "print(len(train_dl), len(val_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "06e4443e-65c1-44ce-b386-aac454451021",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "No CUDA GPUs are available",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mSeq2SeqTransformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28msum\u001b[39m([p\u001b[38;5;241m.\u001b[39mnumel() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mparameters() \u001b[38;5;28;01mif\u001b[39;00m p\u001b[38;5;241m.\u001b[39mrequires_grad]))\n",
      "File \u001b[1;32mc:\\Users\\Nupur\\Documents\\repo\\env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1340\u001b[0m, in \u001b[0;36mModule.to\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1337\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1338\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m-> 1340\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Nupur\\Documents\\repo\\env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:900\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    898\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 900\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    902\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    903\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    904\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    905\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    910\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    911\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Nupur\\Documents\\repo\\env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:900\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    898\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 900\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    902\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    903\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    904\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    905\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    910\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    911\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Nupur\\Documents\\repo\\env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:927\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    923\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[0;32m    924\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[0;32m    925\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[0;32m    926\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m--> 927\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    928\u001b[0m p_should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[0;32m    930\u001b[0m \u001b[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Nupur\\Documents\\repo\\env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1326\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m   1319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[0;32m   1320\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(\n\u001b[0;32m   1321\u001b[0m             device,\n\u001b[0;32m   1322\u001b[0m             dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1323\u001b[0m             non_blocking,\n\u001b[0;32m   1324\u001b[0m             memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format,\n\u001b[0;32m   1325\u001b[0m         )\n\u001b[1;32m-> 1326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1327\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1328\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1329\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1330\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1331\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1332\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot copy out of meta tensor; no data!\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Nupur\\Documents\\repo\\env\\Lib\\site-packages\\torch\\cuda\\__init__.py:319\u001b[0m, in \u001b[0;36m_lazy_init\u001b[1;34m()\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron:\n\u001b[0;32m    318\u001b[0m     os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLAZY\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 319\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    320\u001b[0m \u001b[38;5;66;03m# Some of the queued calls may reentrantly call _lazy_init();\u001b[39;00m\n\u001b[0;32m    321\u001b[0m \u001b[38;5;66;03m# we need to just return without initializing in that case.\u001b[39;00m\n\u001b[0;32m    322\u001b[0m \u001b[38;5;66;03m# However, we must not let any *other* threads in!\u001b[39;00m\n\u001b[0;32m    323\u001b[0m _tls\u001b[38;5;241m.\u001b[39mis_initializing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: No CUDA GPUs are available"
     ]
    }
   ],
   "source": [
    "model = Seq2SeqTransformer(config).to('cuda')\n",
    "print(sum([p.numel() for p in model.parameters() if p.requires_grad]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25dbf599-7448-4e86-b85f-098fd03906c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "best_val_loss = 1e9\n",
    "\n",
    "all_tl = []\n",
    "all_lr = []\n",
    "\n",
    "optim = torch.optim.Adam(model.parameters(),lr=1e-4)\n",
    "sched = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "    optim,\n",
    "    T_0=250,\n",
    "    eta_min=1e-8\n",
    ")\n",
    "\n",
    "scaler = GradScaler('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8f779d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_dl' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i,(a,b,c) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[43mtrain_dl\u001b[49m):\n\u001b[0;32m      2\u001b[0m     src, tgt, labels \u001b[38;5;241m=\u001b[39m a\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m),b\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m),c\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(src)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_dl' is not defined"
     ]
    }
   ],
   "source": [
    "for i,(a,b,c) in enumerate(train_dl):\n",
    "    src, tgt, labels = a.to('cuda'),b.to('cuda'),c.to('cuda')\n",
    "    print(src)\n",
    "    loss = model(src,tgt,labels)\n",
    "    print('loss')\n",
    "    if i ==2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8359c1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f2d875-4dc8-4613-a874-699e686a7b9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "for ep in tqdm(range(epochs)):\n",
    "    model.train()\n",
    "    trl = 0.\n",
    "    #tprog = tqdm(enumerate(train_dl),total=len(train_dl))\n",
    "    for i, (a,b,c) in tqdm(enumerate(train_dl)):\n",
    "        with autocast('cuda'):\n",
    "            src, tgt, labels = a.to('cuda'),b.to('cuda'),c.to('cuda')\n",
    "            loss = model(src,tgt,labels)\n",
    "            print(loss)\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.unscale_(optim)\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), max_norm=2.0, norm_type=2)\n",
    "            scaler.step(optim)\n",
    "            scaler.update()\n",
    "            optim.zero_grad()\n",
    "            sched.step(ep + i / len(train_dl))\n",
    "            all_lr.append(sched.get_last_lr())\n",
    "            trl += loss.item()\n",
    "            all_tl.append(loss.item())\n",
    "            #tprog.set_description(f'train step loss: {loss.item():.4f}')\n",
    "    train_losses.append(trl/len(train_dl))\n",
    "    \n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "        \n",
    "    model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35ae0c3-e1fe-403e-abce-90adaf9c12bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e094b2-31e0-4216-aaee-bf1f51c6b926",
   "metadata": {},
   "outputs": [],
   "source": [
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca42b27-2afa-4390-aff8-f2568b06f413",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (a != config['pad_token_id']).unsqueeze(1).unsqueeze(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a81412b-fe0c-48ae-b46d-6f26f9f41959",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = model(a,b,c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76be17c3-7831-4c53-b732-4d0d11da627e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1dec7f-82db-4ff1-b83f-06e7cebe37c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = EMbedding(config['vocab_size'],config['max_len'],config['dim'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880a1538-cda5-4afc-916b-f6ce72149164",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_emb = embedding(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ebc4fb-5cc9-4fed-8358-0ca4bfee56e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = nn.Linear(config['dim'],config['dim'],bias = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc61467-d3bb-4ae3-9487-5a5717a7a47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = tmp(tmp_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eea0e08-0d82-4dae-81f4-03088b362f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec509f97-b0aa-4ff0-a00b-3a3657b245b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "config['n_heads'],128/4 #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ed6030-2baa-4e16-aaac-009bae3bff27",
   "metadata": {},
   "outputs": [],
   "source": [
    "res.view(2,128,4,32).shape#.permute(0,2,1,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7396b5f6-6328-4c18-a653-04d7541f25a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = res.view(2,128,4,32).permute(0,2,1,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ad9c4b-2db8-4abb-896d-43f979a66354",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = torch.rand(2,4,128,32)\n",
    "v = torch.rand(2,4,128,32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0040d6-3cc9-42f1-8ad1-a837fe16b355",
   "metadata": {},
   "outputs": [],
   "source": [
    "q.shape,k.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff7d25f-662a-45d3-8758-7095480bf927",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = 32 ** -0.5\n",
    "qkT = torch.matmul(q,k.transpose(-1,-2)) * scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b899422-980a-421c-973b-3995d037b20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8cb5b8-8ed3-4bff-8c22-b0c2da963476",
   "metadata": {},
   "outputs": [],
   "source": [
    "qkT.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7300af5-839c-49e6-9d53-8da3273c85c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "k.transpose(-1,-2).shape,q.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7ed35a-cb9e-48ab-89ac-a40594e0218d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = mask.to(dtype=qkT.dtype,device=qkT.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89cb7cfc-22e8-4aba-848a-b5c6a59615c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa,qb = qkT.size(-2), qkT.size(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e90a771-07ca-491e-9654-4958835cf486",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa,qb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82588a2-8bc0-44af-815d-abc3a9a7cce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "qkt = qkT.masked_fill(mask[:,:,:qa,:qb]==0,float('-inf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21990efb-01a6-40da-8cf0-680d00df7ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "attn = torch.matmul(qkT,v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e76562d-61c0-4a70-ac27-d56b6d569072",
   "metadata": {},
   "outputs": [],
   "source": [
    "attn[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e9d9f5-218f-4e7c-8228-eb9e0512b46d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
